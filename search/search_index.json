{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Elevate: model-enhanced LLM driven VUI testing on VPA apps Files Tree \u251c\u2500\u2500 code \u2502 \u251c\u2500\u2500 main.py \u2502 \u251c\u2500\u2500 step1_process_document.py \u2502 \u251c\u2500\u2500 step2_test_skill.py \u2502 \u251c\u2500\u2500 step3_detect_problem.py \u2502 \u251c\u2500\u2500 model \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u251c\u2500\u2500 skill \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u2514\u2500\u2500 util \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 chrome \u2502 \u2514\u2500\u2500 chromedriver_103 \u251c\u2500\u2500 config \u2502 \u2514\u2500\u2500 config000.ini \u251c\u2500\u2500 cookie \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 corpus \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 dataset_2022 \u2502 \u251c\u2500\u2500 benchmark2022.xlsx \u2502 \u2514\u2500\u2500 large_scale.xlsx \u251c\u2500\u2500 README.md \u2514\u2500\u2500 requirement.txt code: contains the source code of Elevate chrome: contains the chromedriver with version 103 config: configuration files. dataset_2022: benchmark skills and large-scale skills requirement.txt: requirements of python packages Requirement python package pip install -r requirement.txt python -m spacy download en_core_web_sm environment export OPENAI_API_KEY=<YOUR OPENAI API KEY> Other the chromedriver that matches your chrome version an amazon developer account that can use the simulator (change the config000.ini in config directory to add your acount) an Azure account that can access to the openAI API (change the config000.ini in config directory to add the apibase and apiversion) We need to login to the amazon developer account to start using the simulator. In most of the cases amazon will send an email to your linked email address for verifications. We use pop to read the emails, so make sure the 110 port is open. How to run Elevate cd code python main.py -i <begin index of skill, default as 1> -ei <end index of skill, default as 100> -c <configuration file name in the config directory, default as config000.ini> -e <input skills file in the dataset_2022 directory, default as benchmark2022.xlsx> -l <path to save communication logs and results, default as ../../output/benchmark_elevate> -d <chromedriver name in the chrome directory, default as chromedriver_103> Result problem.txt: name of skills with problems problem .txt: name of skills with p Download Elevate See the Elevate directory for running Elevate. Dataset can also be found here. Output & Experiment The data for experiments can all be found here. Approaches to run the experiments can be found here .","title":"Home"},{"location":"#elevate-model-enhanced-llm-driven-vui-testing-on-vpa-apps","text":"","title":"Elevate: model-enhanced LLM driven VUI testing on VPA apps"},{"location":"#files-tree","text":"\u251c\u2500\u2500 code \u2502 \u251c\u2500\u2500 main.py \u2502 \u251c\u2500\u2500 step1_process_document.py \u2502 \u251c\u2500\u2500 step2_test_skill.py \u2502 \u251c\u2500\u2500 step3_detect_problem.py \u2502 \u251c\u2500\u2500 model \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u251c\u2500\u2500 skill \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u2514\u2500\u2500 util \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 chrome \u2502 \u2514\u2500\u2500 chromedriver_103 \u251c\u2500\u2500 config \u2502 \u2514\u2500\u2500 config000.ini \u251c\u2500\u2500 cookie \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 corpus \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 dataset_2022 \u2502 \u251c\u2500\u2500 benchmark2022.xlsx \u2502 \u2514\u2500\u2500 large_scale.xlsx \u251c\u2500\u2500 README.md \u2514\u2500\u2500 requirement.txt code: contains the source code of Elevate chrome: contains the chromedriver with version 103 config: configuration files. dataset_2022: benchmark skills and large-scale skills requirement.txt: requirements of python packages","title":"Files Tree"},{"location":"#requirement","text":"","title":"Requirement"},{"location":"#python-package","text":"pip install -r requirement.txt python -m spacy download en_core_web_sm","title":"python package"},{"location":"#environment","text":"export OPENAI_API_KEY=<YOUR OPENAI API KEY>","title":"environment"},{"location":"#other","text":"the chromedriver that matches your chrome version an amazon developer account that can use the simulator (change the config000.ini in config directory to add your acount) an Azure account that can access to the openAI API (change the config000.ini in config directory to add the apibase and apiversion) We need to login to the amazon developer account to start using the simulator. In most of the cases amazon will send an email to your linked email address for verifications. We use pop to read the emails, so make sure the 110 port is open.","title":"Other"},{"location":"#how-to-run-elevate","text":"cd code python main.py -i <begin index of skill, default as 1> -ei <end index of skill, default as 100> -c <configuration file name in the config directory, default as config000.ini> -e <input skills file in the dataset_2022 directory, default as benchmark2022.xlsx> -l <path to save communication logs and results, default as ../../output/benchmark_elevate> -d <chromedriver name in the chrome directory, default as chromedriver_103>","title":"How to run Elevate"},{"location":"#result","text":"problem.txt: name of skills with problems problem .txt: name of skills with p","title":"Result"},{"location":"#download","text":"Elevate See the Elevate directory for running Elevate. Dataset can also be found here. Output & Experiment The data for experiments can all be found here. Approaches to run the experiments can be found here .","title":"Download"},{"location":"experiment/","text":"Experiment Download experiment to do experiments. The elevate_10min, gpt4_chatbot_10min, vitas_10min show the communication logs for Elevate, GPT4(chatbot) and Vitas to test skills for 10 minutes. The elevate12+vitas3_10min, elevate13+vitas2_10min, elevate23+vitas1_10min are for ablation studies. The elevate+llama2_10min and llama2_chatbot_10min are communication logs of Elevate+Llama2_13b and Llama2-13b(chatbot) respectively. The large_scale contains the communciation logs and problem lists of skills in large-scale dataset. The user contains the commucation logs of our user study. The experiment.py file is the source code to do experiments. Study1 and Study2 Figure6-8 show the comparison of state space coverage between Elevate, GPT4(chatbot) and Vitas. Figure9-10 show the distribution of interaction rounds between Elevate and GPT4(chatbot), Elevate and Vitas respectively. It is important to note that the results here show the communication logs of each tool testing 10 minutes. But in the study1 we compare the state space coverage of each tool testing for the same number of interaction rounds. To get the state coverage and efficiency achieved by Elevate and the baselines, run: python experiment.py 1 The result will be shown in study1&2_coverage_efficiency_gpt4_elevate.xlsx , study1&2_coverage_efficiency_vitas_elevate.xlsx and study1&2_coverage_efficiency_vitas_gpt4.xlsx . Study3 Table 5 show the number of problems detected by Elevate and the baselines. The problem lists are shown in the result directory. To get the problems detected by Elevate and the baselines, run: python experiment.py 3 The result will be shown in study3_problems.xlsx . Study4 Figure 11-13 show the comparison of state space coverage between Elevate and Elevate( P input + P explr ), Elevate( P state + P explr ) and Elevate( P state + P inputsub> ). To get their state space coverage, run: python experiment.py 4 The result will be shown in study4.1_ablation_1.xlsx , study4.2_ablation_2.xlsx and study4.3_ablation_3.xlsx . Study5 Figure 14 shows the comparison of state space coverage between Gavin+Llama2-13b and Llama-13b(chatbot). To get their state space coverage, run: python experiment.py 5 The result will be shown in study5_coverage_llama2_elevate.xlsx . Study6 Table 6 shows the landscape of problems on the large-scale dataset. The problems are recorded in the result directory of each category's directory. To get the distribution of problems, run: python experiment.py 6 The result will be shown in study6_problems.xlsx . Discussion Figure 15 shows the comparison of state space coverage between user, Elevate and Vitas. To get their state space coverage and the intersactions, run: python experiment.py 7 The result will be shown in discussion_coverage_user_vitas_elevate.xlsx .","title":"Experiment"},{"location":"experiment/#experiment","text":"Download experiment to do experiments. The elevate_10min, gpt4_chatbot_10min, vitas_10min show the communication logs for Elevate, GPT4(chatbot) and Vitas to test skills for 10 minutes. The elevate12+vitas3_10min, elevate13+vitas2_10min, elevate23+vitas1_10min are for ablation studies. The elevate+llama2_10min and llama2_chatbot_10min are communication logs of Elevate+Llama2_13b and Llama2-13b(chatbot) respectively. The large_scale contains the communciation logs and problem lists of skills in large-scale dataset. The user contains the commucation logs of our user study. The experiment.py file is the source code to do experiments.","title":"Experiment"},{"location":"experiment/#study1-and-study2","text":"Figure6-8 show the comparison of state space coverage between Elevate, GPT4(chatbot) and Vitas. Figure9-10 show the distribution of interaction rounds between Elevate and GPT4(chatbot), Elevate and Vitas respectively. It is important to note that the results here show the communication logs of each tool testing 10 minutes. But in the study1 we compare the state space coverage of each tool testing for the same number of interaction rounds. To get the state coverage and efficiency achieved by Elevate and the baselines, run: python experiment.py 1 The result will be shown in study1&2_coverage_efficiency_gpt4_elevate.xlsx , study1&2_coverage_efficiency_vitas_elevate.xlsx and study1&2_coverage_efficiency_vitas_gpt4.xlsx .","title":"Study1 and Study2"},{"location":"experiment/#study3","text":"Table 5 show the number of problems detected by Elevate and the baselines. The problem lists are shown in the result directory. To get the problems detected by Elevate and the baselines, run: python experiment.py 3 The result will be shown in study3_problems.xlsx .","title":"Study3"},{"location":"experiment/#study4","text":"Figure 11-13 show the comparison of state space coverage between Elevate and Elevate( P input + P explr ), Elevate( P state + P explr ) and Elevate( P state + P inputsub> ). To get their state space coverage, run: python experiment.py 4 The result will be shown in study4.1_ablation_1.xlsx , study4.2_ablation_2.xlsx and study4.3_ablation_3.xlsx .","title":"Study4"},{"location":"experiment/#study5","text":"Figure 14 shows the comparison of state space coverage between Gavin+Llama2-13b and Llama-13b(chatbot). To get their state space coverage, run: python experiment.py 5 The result will be shown in study5_coverage_llama2_elevate.xlsx .","title":"Study5"},{"location":"experiment/#study6","text":"Table 6 shows the landscape of problems on the large-scale dataset. The problems are recorded in the result directory of each category's directory. To get the distribution of problems, run: python experiment.py 6 The result will be shown in study6_problems.xlsx .","title":"Study6"},{"location":"experiment/#discussion","text":"Figure 15 shows the comparison of state space coverage between user, Elevate and Vitas. To get their state space coverage and the intersactions, run: python experiment.py 7 The result will be shown in discussion_coverage_user_vitas_elevate.xlsx .","title":"Discussion"}]}