{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Elevate: model-enhanced LLM driven VUI testing on VPA apps Files Tree \u251c\u2500\u2500 code \u2502 \u251c\u2500\u2500 main.py \u2502 \u251c\u2500\u2500 step1_process_document.py \u2502 \u251c\u2500\u2500 step2_test_skill.py \u2502 \u251c\u2500\u2500 step3_detect_problem.py \u2502 \u251c\u2500\u2500 model \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u251c\u2500\u2500 skill \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u2514\u2500\u2500 util \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 chrome \u2502 \u2514\u2500\u2500 chromedriver_new.exe \u251c\u2500\u2500 config \u2502 \u2514\u2500\u2500 config000.ini \u251c\u2500\u2500 cookie \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 corpus \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 dataset_2022 \u2502 \u251c\u2500\u2500 benchmark.xlsx \u2502 \u2514\u2500\u2500 large_scale_4000.xlsx \u251c\u2500\u2500 README.md \u2514\u2500\u2500 requirement.txt code: contains the source code of Elevate chrome: contains the current chromedriver on windows (24th, March, 2024) config: configuration files. dataset_2022: benchmark skills and large-scale skills requirement.txt: requirements of python packages Requirement python package pip install -r requirement.txt python -m spacy download en_core_web_sm environment export OPENAI_API_KEY=<YOUR OPENAI API KEY> Other the chromedriver that matches your chrome version an amazon developer account that can use the simulator (change the config000.ini in config directory to add your acount) an Azure account that can access to the openAI API (change the config000.ini in config directory to add the apibase and apiversion) We need to login to the amazon developer account to start using the simulator. In most of the cases amazon will send an email to your linked email address for verifications. We use pop to read the emails, so make sure the 110 port is open. How to run Elevate cd code python main.py -i <begin index of skill, default as 1> -ei <end index of skill, default as 100> -c <configuration file name in the config directory, default as config000.ini> -e <input skills file in the dataset_2022 directory, default as benchmark.xlsx> -l <path to save communication logs and results, default as ../../output/benchmark> -d <chromedriver name in the chrome directory, default as chromedriver_new.exe> Download Elevate See the Elevate directory for running Elevate. Dataset can also be found here. Output & Experiment The data for experiments can all be found here. Approaches to run the experiments can be found here .","title":"Home"},{"location":"#elevate-model-enhanced-llm-driven-vui-testing-on-vpa-apps","text":"","title":"Elevate: model-enhanced LLM driven VUI testing on VPA apps"},{"location":"#files-tree","text":"\u251c\u2500\u2500 code \u2502 \u251c\u2500\u2500 main.py \u2502 \u251c\u2500\u2500 step1_process_document.py \u2502 \u251c\u2500\u2500 step2_test_skill.py \u2502 \u251c\u2500\u2500 step3_detect_problem.py \u2502 \u251c\u2500\u2500 model \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u251c\u2500\u2500 skill \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u2514\u2500\u2500 util \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 chrome \u2502 \u2514\u2500\u2500 chromedriver_new.exe \u251c\u2500\u2500 config \u2502 \u2514\u2500\u2500 config000.ini \u251c\u2500\u2500 cookie \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 corpus \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 dataset_2022 \u2502 \u251c\u2500\u2500 benchmark.xlsx \u2502 \u2514\u2500\u2500 large_scale_4000.xlsx \u251c\u2500\u2500 README.md \u2514\u2500\u2500 requirement.txt code: contains the source code of Elevate chrome: contains the current chromedriver on windows (24th, March, 2024) config: configuration files. dataset_2022: benchmark skills and large-scale skills requirement.txt: requirements of python packages","title":"Files Tree"},{"location":"#requirement","text":"","title":"Requirement"},{"location":"#python-package","text":"pip install -r requirement.txt python -m spacy download en_core_web_sm","title":"python package"},{"location":"#environment","text":"export OPENAI_API_KEY=<YOUR OPENAI API KEY>","title":"environment"},{"location":"#other","text":"the chromedriver that matches your chrome version an amazon developer account that can use the simulator (change the config000.ini in config directory to add your acount) an Azure account that can access to the openAI API (change the config000.ini in config directory to add the apibase and apiversion) We need to login to the amazon developer account to start using the simulator. In most of the cases amazon will send an email to your linked email address for verifications. We use pop to read the emails, so make sure the 110 port is open.","title":"Other"},{"location":"#how-to-run-elevate","text":"cd code python main.py -i <begin index of skill, default as 1> -ei <end index of skill, default as 100> -c <configuration file name in the config directory, default as config000.ini> -e <input skills file in the dataset_2022 directory, default as benchmark.xlsx> -l <path to save communication logs and results, default as ../../output/benchmark> -d <chromedriver name in the chrome directory, default as chromedriver_new.exe>","title":"How to run Elevate"},{"location":"#download","text":"Elevate See the Elevate directory for running Elevate. Dataset can also be found here. Output & Experiment The data for experiments can all be found here. Approaches to run the experiments can be found here .","title":"Download"},{"location":"experiment/","text":"Experiment Download experiment to do experiments. The elevate_10min, gpt4_chatbot_10min, vitas_10min show the communication logs for Elevate, GPT4(chatbot) and Vitas to test skills for 10 minutes. The ablation1, ablation2, ablation are for ablation studies. The elevate+llama2-70b-chat-hf_10min and llama2-70b-chat-hf_chatbot_10min are communication logs of Elevate-Llama2-70b-chat and Llama2-70b-chat(chatbot) respectively. The large_scale contains the communciation logs of skills in large-scale dataset. The user contains the commucation logs of our user study. The experiment.py file is the source code to do experiments. Study1 Figure 7 shows the comparison of sentence states and semantic states covered by Elevate, GPT4(chatbot) and Vitas. Figure 8 shows the average semantic state coverage rate with varying interaction rounds between Elevate and baselines. It is important to note that the results here show the communication logs of each tool testing 10 minutes. But in the study 1 we compare the semantic state coverage rate of each tool testing for the same number of interaction rounds. To get the semantic/sentence states and average semantic state coverage rate achieved by Elevate and the baselines, run: python experiment.py 1 The results will be shown in study1_1_.xlsx and study1_2.xlsx . Study2 Figure 9 shows the average semantic state coverage rate by Elevate, w/o States extraction, w/o Input events generation and w/o State space exploration. To get the raw data of the ablation study, run: python experiment.py 2 The result will be shown in study2.xlsx . Study3 Figure 10 shows the average semantic state coverage rate achieved by Elevate-Llama2-70b-chat, Vitas and Llama2-70b-chat(chatbot). To get their state coverage rate on the benchmark, run: python experiment.py 3 The result will be shown in study3.xlsx . Study4 Figure 11 shows the comparison of coverage rate achieved by Elevate and Vitas on 4000 skills from all categories. To get the coverage rate of Elevate and Vitas on these 4000 skills, run: python experiment.py 4 The result will be shown in study4.xlsx .","title":"Experiment"},{"location":"experiment/#experiment","text":"Download experiment to do experiments. The elevate_10min, gpt4_chatbot_10min, vitas_10min show the communication logs for Elevate, GPT4(chatbot) and Vitas to test skills for 10 minutes. The ablation1, ablation2, ablation are for ablation studies. The elevate+llama2-70b-chat-hf_10min and llama2-70b-chat-hf_chatbot_10min are communication logs of Elevate-Llama2-70b-chat and Llama2-70b-chat(chatbot) respectively. The large_scale contains the communciation logs of skills in large-scale dataset. The user contains the commucation logs of our user study. The experiment.py file is the source code to do experiments.","title":"Experiment"},{"location":"experiment/#study1","text":"Figure 7 shows the comparison of sentence states and semantic states covered by Elevate, GPT4(chatbot) and Vitas. Figure 8 shows the average semantic state coverage rate with varying interaction rounds between Elevate and baselines. It is important to note that the results here show the communication logs of each tool testing 10 minutes. But in the study 1 we compare the semantic state coverage rate of each tool testing for the same number of interaction rounds. To get the semantic/sentence states and average semantic state coverage rate achieved by Elevate and the baselines, run: python experiment.py 1 The results will be shown in study1_1_.xlsx and study1_2.xlsx .","title":"Study1"},{"location":"experiment/#study2","text":"Figure 9 shows the average semantic state coverage rate by Elevate, w/o States extraction, w/o Input events generation and w/o State space exploration. To get the raw data of the ablation study, run: python experiment.py 2 The result will be shown in study2.xlsx .","title":"Study2"},{"location":"experiment/#study3","text":"Figure 10 shows the average semantic state coverage rate achieved by Elevate-Llama2-70b-chat, Vitas and Llama2-70b-chat(chatbot). To get their state coverage rate on the benchmark, run: python experiment.py 3 The result will be shown in study3.xlsx .","title":"Study3"},{"location":"experiment/#study4","text":"Figure 11 shows the comparison of coverage rate achieved by Elevate and Vitas on 4000 skills from all categories. To get the coverage rate of Elevate and Vitas on these 4000 skills, run: python experiment.py 4 The result will be shown in study4.xlsx .","title":"Study4"},{"location":"supporting_results/","text":"Supporting results Average sentence state coverage rate with interaction rounds In Study 1, we compare the average semantic state coverage rate with varying interaction rounds between Elevate and baselines. Semantic states are acquired by merging sentence states with similar functionalities or behavior. To demonstrate that Elevate outperforms baselines under different metrics, we compare the average sentence state coverage rate with varying interaction rounds in this study. The total state space is set as the unique sentence states achieved by Elevate and baselines. The result is shown below. Under the metric of sentence states, Elevate still achieves 10% higher average coverage rate than Vitas in a more efficient manner. Average semantic state coverage rate with interaction rounds (total state space includes states of manual testing) The total state space is set as the unique semantic states achieved by Elevate, Vitas, GPT-4(chatbot) and manual testing . Then, the semantic state coverage rate with varying interaction rounds is compared between Elevate and baselines. The result is shown below. When manual testing results are considered in the total state space, Elevage still achieves an average coverage rate of nearly 70% and supasses baselines. Problems found by Elevate on 4000 skills As summaried by Vitas, five common problems exist on VPA apps: unexpected exit, privacy violation, unable to exit, expected started apps and unavailable apps. Hence, Elevate supports checking these five problems while exploring VPA apps' behavior. The problems found on the large scale dataset by Elevate are shown below. category apps with problems unexpected exit privacy violation unable to exit expected started apps unavailable apps Business_Finance 187 121 11 13 6 55 Connected_Car 15 5 1 2 0 8 Education_Reference 330 209 8 8 25 105 Food_Drink 167 123 5 7 3 39 Games_Trivia 453 207 7 12 27 230 Health_Fitness 106 62 2 0 8 39 Kids 161 37 1 0 14 117 Lifestyle 334 199 10 5 18 118 Local 17 11 0 0 0 6 Movies_TV 20 11 0 1 2 8 Music_Audio 2 2 0 0 0 0 News 132 87 0 3 6 41 Novelty_Humor 600 436 7 6 29 138 Productivity 158 85 7 16 9 59 Shopping 55 28 4 3 1 21 Smart_Home 346 90 2 36 9 263 Social 171 85 5 5 14 72 Sports 58 22 1 0 7 30 Travel_Transportation 110 61 2 7 3 44 Utilities 137 81 5 7 9 47 Weather 72 46 3 3 4 20 Total 3631 2008 81 134 194 1460 Surprisingly, most of skills are detected with problems. A large number of them suffer from unexpected exit. Comparison of state space achieved by Elevate, Vitas and Manual testing To show the intersection state space between Elevate, Vitas and Manual testing, we draw the venn diagram. The text on each part represents the state space coverage rate when the unique states achieved by Elevate, Vitas and Manual testing is set as the total space. The result is shown below. Compared with Vitas, Elevate covers more state space discovered by manual testing, which proves that Elevate works more like a manual tester. To further analyze the characteristics of states achieved by Elevate and Vitas, we extract meaningful states, which represent the normal behavior of skills. Meaningful states are extracted manually from the states achieved by Elevate and Vitas. The venn diagram of meaningful states coverage by Elevate and Vitas is shown below. The figure demonstrate that Elevate achieves more meaningful states than Vitas. It proves that input events generated by Elevate are more effective in exploring apps' functionalities.","title":"Supporting results"},{"location":"supporting_results/#supporting-results","text":"","title":"Supporting results"},{"location":"supporting_results/#average-sentence-state-coverage-rate-with-interaction-rounds","text":"In Study 1, we compare the average semantic state coverage rate with varying interaction rounds between Elevate and baselines. Semantic states are acquired by merging sentence states with similar functionalities or behavior. To demonstrate that Elevate outperforms baselines under different metrics, we compare the average sentence state coverage rate with varying interaction rounds in this study. The total state space is set as the unique sentence states achieved by Elevate and baselines. The result is shown below. Under the metric of sentence states, Elevate still achieves 10% higher average coverage rate than Vitas in a more efficient manner.","title":"Average sentence state coverage rate with interaction rounds"},{"location":"supporting_results/#average-semantic-state-coverage-rate-with-interaction-rounds-total-state-space-includes-states-of-manual-testing","text":"The total state space is set as the unique semantic states achieved by Elevate, Vitas, GPT-4(chatbot) and manual testing . Then, the semantic state coverage rate with varying interaction rounds is compared between Elevate and baselines. The result is shown below. When manual testing results are considered in the total state space, Elevage still achieves an average coverage rate of nearly 70% and supasses baselines.","title":"Average semantic state coverage rate with interaction rounds (total state space includes states of manual testing)"},{"location":"supporting_results/#problems-found-by-elevate-on-4000-skills","text":"As summaried by Vitas, five common problems exist on VPA apps: unexpected exit, privacy violation, unable to exit, expected started apps and unavailable apps. Hence, Elevate supports checking these five problems while exploring VPA apps' behavior. The problems found on the large scale dataset by Elevate are shown below. category apps with problems unexpected exit privacy violation unable to exit expected started apps unavailable apps Business_Finance 187 121 11 13 6 55 Connected_Car 15 5 1 2 0 8 Education_Reference 330 209 8 8 25 105 Food_Drink 167 123 5 7 3 39 Games_Trivia 453 207 7 12 27 230 Health_Fitness 106 62 2 0 8 39 Kids 161 37 1 0 14 117 Lifestyle 334 199 10 5 18 118 Local 17 11 0 0 0 6 Movies_TV 20 11 0 1 2 8 Music_Audio 2 2 0 0 0 0 News 132 87 0 3 6 41 Novelty_Humor 600 436 7 6 29 138 Productivity 158 85 7 16 9 59 Shopping 55 28 4 3 1 21 Smart_Home 346 90 2 36 9 263 Social 171 85 5 5 14 72 Sports 58 22 1 0 7 30 Travel_Transportation 110 61 2 7 3 44 Utilities 137 81 5 7 9 47 Weather 72 46 3 3 4 20 Total 3631 2008 81 134 194 1460 Surprisingly, most of skills are detected with problems. A large number of them suffer from unexpected exit.","title":"Problems found by Elevate on 4000 skills"},{"location":"supporting_results/#comparison-of-state-space-achieved-by-elevate-vitas-and-manual-testing","text":"To show the intersection state space between Elevate, Vitas and Manual testing, we draw the venn diagram. The text on each part represents the state space coverage rate when the unique states achieved by Elevate, Vitas and Manual testing is set as the total space. The result is shown below. Compared with Vitas, Elevate covers more state space discovered by manual testing, which proves that Elevate works more like a manual tester. To further analyze the characteristics of states achieved by Elevate and Vitas, we extract meaningful states, which represent the normal behavior of skills. Meaningful states are extracted manually from the states achieved by Elevate and Vitas. The venn diagram of meaningful states coverage by Elevate and Vitas is shown below. The figure demonstrate that Elevate achieves more meaningful states than Vitas. It proves that input events generated by Elevate are more effective in exploring apps' functionalities.","title":"Comparison of state space achieved by Elevate, Vitas and Manual testing"}]}